{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vendor:  Continuum Analytics, Inc.\n",
      "Package: mkl\n",
      "Message: trial mode expires in 23 days\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from matplotlib import rc\n",
    "\n",
    "fontsize = 12\n",
    "\n",
    "# Make default font serif\n",
    "rc('font', family=b'serif', size=fontsize)\n",
    "# Hide legend frame, change size, make only one scatter marker show up\n",
    "rc('legend', borderpad=0.,labelspacing=0.25, fontsize=(fontsize - 1.), frameon=False, numpoints=1)\n",
    "# Default line width (e.g. for plot()) should be thinner than 1 point\n",
    "rc('patch', linewidth=0.75)\n",
    "rc('lines', linewidth=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BW1484 Core I Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_ref = 1.00020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denovo ouput file processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "class DenovoProcessor(object):\n",
    "    \"\"\"DenovoProcessor class: processes an output file from a Denovo calculation.\n",
    "       It can read a file, print that information to csv, and do some processing\n",
    "       for highlights.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Set information we'll use in processing a Denovo output file\"\"\"    \n",
    "        # Output variables that are in the header / problem specification\n",
    "        self.keys = ['problem_name', 'num cells I', 'num cells J', 'num cells K', 'cells', 'mesh ',\n",
    "                     'num_blocks_i', 'num_blocks_j', 'num_z_blocks', 'blocks', 'num_groups', \n",
    "                     'num upscatter groups', 'num_sets', 'domains', 'Pn_order', 'azimuthals_octant', \n",
    "                     'polars_octant', 'eq_set', 'DoF', 'tolerance', 'L2_tolerance', 'k_tolerance',\n",
    "                     'up_tol', 'eigen_solver', 'mg_preconditioner', 'relax_count', 'num_v_cycles', \n",
    "                     'relax_weight', 'ml_Pn', 'ml_az', 'ml_oct']\n",
    "        # Information about timing and processor distribution\n",
    "        self.time_keys = ['procs-per-node-x', 'procs-per-node-y', 'walltime']\n",
    "        # Iteration information that is printed during execution\n",
    "        self.iter_dict = {'Iterations =' : [], 'Eigenvalue Iteration   ' : [],\n",
    "                           'relative error in k-eff of ' : [],\n",
    "                           'absolute error in k-eff of ' : []}  \n",
    "        \n",
    "                \n",
    "    def parse_file(self, out_file):\n",
    "        \"\"\"Read the values for the keys from out_file\"\"\"\n",
    "        # Initalize values to match keys to None\n",
    "        self.vals = {key: None for key in keys}\n",
    "        self.time_vals = {key: None for key in time_keys}\n",
    "    \n",
    "        # Set flags and keys to use for items with duplicate entries\n",
    "        ml_flag = False\n",
    "        ml_keys = ['Pn_order', 'azimuthals_octant', 'polars_octant']\n",
    "        ml_doubles = {key: None for key in ml_keys}\n",
    "        ml_cnt = 0\n",
    "        up_db = False\n",
    "        doubles = {'tolerance' : None}\n",
    "    \n",
    "        # open the file\n",
    "        if os.path.isfile(out_file):\n",
    "            f = open(out_file, 'r')\n",
    "        else:\n",
    "            raise IOError('could not find file', full_out_file)\n",
    "   \n",
    "        # Process the file\n",
    "        for line in f:\n",
    "    \n",
    "            # check for the duplicate items before processing everything else\n",
    "            if ml_flag == True: \n",
    "                if ml_cnt != 3:\n",
    "                    for ml_key in ml_doubles:\n",
    "                        if re.search(ml_key, line):\n",
    "                            if ml_doubles[ml_key] == None:\n",
    "                                data = line.split(ml_key)\n",
    "                                ml_doubles[ml_key] = data[1].strip() \n",
    "                                ml_cnt = ml_cnt + 1\n",
    "                else:\n",
    "                    ml_flag = False\n",
    "            if up_db == True:\n",
    "                if re.search('tolerance', line):\n",
    "                    if doubles['tolerance'] == None:\n",
    "                        data = line.split('tolerance')\n",
    "                        doubles['tolerance'] = data[1].strip() \n",
    "                        up_db = False\n",
    "    \n",
    "            # Information in the header\n",
    "            for key in self.vals: \n",
    "                # check for things to set the flags\n",
    "                if re.search('multilevel_quad_db', line):\n",
    "                    ml_flag = True\n",
    "                if re.search('upscatter_db', line):\n",
    "                    up_db = True   \n",
    "                # now look for the rest of the keys\n",
    "                if re.search(key, line):\n",
    "                    data = line.split(key)\n",
    "                    self.vals[key] = data[1].strip()  \n",
    "            \n",
    "            # Time and CUDA information\n",
    "            for key in time_vals:\n",
    "                if re.search(key, line):\n",
    "                    data = line.split(key)\n",
    "                    num = data[1].strip().split()\n",
    "                    self.time_vals[key] = num[0].strip()\n",
    "            \n",
    "            # Iteration information\n",
    "            for key in iter_dict:\n",
    "                if re.search(key, line):\n",
    "                    data = line.split(key)\n",
    "                    num = data[1].strip().split()\n",
    "                    self.iter_dict[key].append(num[0].strip())\n",
    "        \n",
    "        # calculate things we want in the spreadsheet\n",
    "        self.vals['cells']   = int(self.vals['num cells I']) * int(self.vals['num cells J']) * int(self.vals['num cells K'])\n",
    "        self.vals['blocks']  = int(self.vals['num_blocks_i']) * int(self.vals['num_blocks_j'])\n",
    "        self.vals['domains'] = int(self.vals['blocks']) * int(self.vals['num_sets'])\n",
    "        # set doubles\n",
    "        self.vals['ml_Pn']  = ml_doubles['Pn_order']\n",
    "        self.vals['ml_az']  = ml_doubles['azimuthals_octant']\n",
    "        self.vals['ml_oct'] = ml_doubles['polars_octant']\n",
    "        self.vals['up_tol'] = doubles['tolerance']\n",
    "\n",
    "        \n",
    "        \n",
    "    def print_csv(self,name):\n",
    "        \"\"\"Print the read in data to name.csv\"\"\"\n",
    "\n",
    "        # itereation keys we'd like to print since they have nicer names\n",
    "        iter_keys = ['eigen_iters', 'rel_err_k', 'abs_err_k', 'fxd_iters']\n",
    "        # How the keys map to the keys that we used on read-in from the file\n",
    "        key_map = {'fxd_iters' : 'Iterations =', 'eigen_iters' : 'Eigenvalue Iteration   ', \n",
    "                   'rel_err_k' : 'relative error in k-eff of ', \n",
    "                   'abs_err_k' : 'absolute error in k-eff of '}\n",
    "\n",
    "        with open(name+'.csv', 'wb') as csvfile:\n",
    "            # write the header / problem specification information\n",
    "            writer = csv.DictWriter(csvfile, fieldnames = self.keys, dialect='excel', \n",
    "                                    restval='',extrasaction='ignore')\n",
    "            #if not csv.Sniffer().has_header(csvfile.read(1024)):\n",
    "            writer.writeheader()\n",
    "            writer.writerow(vals)\n",
    "    \n",
    "            # Now write timing information\n",
    "            writer = csv.DictWriter(csvfile, fieldnames = self.time_keys, dialect='excel', \n",
    "                                    restval='',extrasaction='ignore')\n",
    "            writer.writeheader()\n",
    "            writer.writerow(time_vals)\n",
    "    \n",
    "            # And iteration information\n",
    "            writer = csv.DictWriter(csvfile, fieldnames = iter_keys, dialect='excel', \n",
    "                                    restval='',extrasaction='ignore')\n",
    "            writer.writeheader()\n",
    "            length = len(self.iter_dict[key_map[iter_keys[0]]])\n",
    "            for row_num in range(length):\n",
    "                # get a new dictionary that will contain one row of data at each new row\n",
    "                tmp_dict = {}\n",
    "                for key in iter_keys:\n",
    "                    tmp_dict[key] = self.iter_dict[key_map[key]][row_num]\n",
    "                writer.writerow(tmp_dict)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process a bunch of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Name of the file containing the output we want to process \n",
    "file_location = '/home/slayer/Dropbox/Software/Exnihilo/Calculations/bw1484/'\n",
    "file_name='bw1484_small.out' \n",
    "full_out_file = os.path.join(file_location, file_name)\n",
    "\n",
    "# Get a DenovoProcessor, parse the file, and write to csv\n",
    "processor = DenovoProcessor()\n",
    "processor.parse_file(full_out_file)\n",
    "processor.print_csv('bw1484_small')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
