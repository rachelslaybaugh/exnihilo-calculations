{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vendor:  Continuum Analytics, Inc.\n",
      "Package: mkl\n",
      "Message: trial mode expires in 30 days\n"
     ]
    }
   ],
   "source": [
    "#import pandas as pd\n",
    "#import string\n",
    "from matplotlib import rc\n",
    "\n",
    "fontsize = 12\n",
    "\n",
    "# Make default font serif\n",
    "rc('font', family=b'serif', size=fontsize)\n",
    "# Hide legend frame, change size, make only one scatter marker show up\n",
    "rc('legend', borderpad=0.,labelspacing=0.25, fontsize=(fontsize - 1.), frameon=False, numpoints=1)\n",
    "# Default line width (e.g. for plot()) should be thinner than 1 point\n",
    "rc('patch', linewidth=0.75)\n",
    "rc('lines', linewidth=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BW1484 Core I Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_ref = 1.00020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and parse the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# name of the file containing the output we want to process; \n",
    "# figure out how to make this a command line option later\n",
    "out_file='bw1484_small.out' #$1\n",
    "full_out_file = os.path.join('/home/slayer/Dropbox/Software/Exnihilo/Calculations/bw1484/',\n",
    "                            out_file)\n",
    "if os.path.isfile(full_out_file):\n",
    "    f = open(full_out_file, 'r')\n",
    "else:\n",
    "    raise IOError('could not find file', full_out_file)\n",
    "\n",
    "# Pairs of output variables that are in the header / problem specification\n",
    "keys = ['problem_name', 'num cells I', 'num cells J', 'num cells K', 'cells', 'mesh ',\n",
    "        'num_blocks_i', 'num_blocks_j', 'num_z_blocks', 'blocks', 'num_groups', \n",
    "        'num upscatter groups', 'num_sets', 'domains', 'Pn_order', 'azimuthals_octant', \n",
    "        'polars_octant', 'eq_set', 'DoF', 'tolerance', 'L2_tolerance', 'k_tolerance',\n",
    "        'up_tol', 'eigen_solver', 'mg_preconditioner', 'relax_count', 'num_v_cycles', \n",
    "        'relax_weight', 'ml_Pn', 'ml_az', 'ml_oct']\n",
    "vals = {key: None for key in keys}\n",
    "\n",
    "\n",
    "time_keys = ['procs-per-node-x', 'procs-per-node-y', 'walltime']\n",
    "time_vals = {key: None for key in time_keys}\n",
    "\n",
    "# Iteration information\n",
    "key_map = {'fxd_iters' : 'Iterations =',# 'fxd_res' : '[ 0 ] =', \n",
    "           'eigen_iters' : 'Eigenvalue Iteration   ', \n",
    "           'rel_err_k' : 'relative error in k-eff of ', \n",
    "           'abs_err_k' : 'absolute error in k-eff of '}\n",
    "iter_dict = {'Iterations =' : [],# '[ 0 ] =' : [],\n",
    "             'Eigenvalue Iteration   ' : [], 'relative error in k-eff of ' : [],\n",
    "             'absolute error in k-eff of ' : []}\n",
    "\n",
    "# set flags and keys to use for items with duplicate entries\n",
    "ml_flag = False\n",
    "ml_keys = ['Pn_order', 'azimuthals_octant', 'polars_octant']\n",
    "ml_doubles = {key: None for key in ml_keys}\n",
    "ml_cnt = 0\n",
    "up_db = False\n",
    "doubles = {'tolerance' : None}\n",
    "\n",
    "for line in f:\n",
    "    \n",
    "    # check for the duplicate items before processing the next stuff\n",
    "    if ml_flag == True: \n",
    "        if ml_cnt != 3:\n",
    "            for ml_key in ml_doubles:\n",
    "                if re.search(ml_key, line):\n",
    "                    if ml_doubles[ml_key] == None:\n",
    "                        data = line.split(ml_key)\n",
    "                        ml_doubles[ml_key] = data[1].strip() \n",
    "                        ml_cnt = ml_cnt + 1\n",
    "        else:\n",
    "            ml_flag = False\n",
    "    if up_db == True:\n",
    "        if re.search('tolerance', line):\n",
    "            if doubles['tolerance'] == None:\n",
    "                data = line.split('tolerance')\n",
    "                doubles['tolerance'] = data[1].strip() \n",
    "                up_db = False\n",
    "    \n",
    "    # Information in the header\n",
    "    for key in vals: \n",
    "        # check for things to set the flags\n",
    "        if re.search('multilevel_quad_db', line):\n",
    "            ml_flag = True\n",
    "        if re.search('upscatter_db', line):\n",
    "            up_db = True   \n",
    "        # now look for the rest of the keys\n",
    "        if re.search(key, line):\n",
    "            data = line.split(key)\n",
    "            vals[key] = data[1].strip()  \n",
    "            \n",
    "    # Time and CUDA information\n",
    "    for key in time_vals:\n",
    "        if re.search(key, line):\n",
    "            data = line.split(key)\n",
    "            num = data[1].strip().split()\n",
    "            time_vals[key] = num[0].strip()\n",
    "            \n",
    "    # Iteration information\n",
    "    for key in iter_dict:\n",
    "        if re.search(key, line):\n",
    "            data = line.split(key)\n",
    "            num = data[1].strip().split()\n",
    "            iter_dict[key].append(num[0].strip())\n",
    "        \n",
    "# calculate things we want in the spreadsheet\n",
    "vals['cells'] = int(vals['num cells I']) * int(vals['num cells J']) * int(vals['num cells K'])\n",
    "vals['blocks'] = int(vals['num_blocks_i']) * int(vals['num_blocks_j'])\n",
    "vals['domains'] = int(vals['blocks']) * int(vals['num_sets'])\n",
    "# set doubles\n",
    "vals['ml_Pn'] = ml_doubles['Pn_order']\n",
    "vals['ml_az'] = ml_doubles['azimuthals_octant']\n",
    "vals['ml_oct'] = ml_doubles['polars_octant']\n",
    "vals['up_tol'] = doubles['tolerance']\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### print information to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Reorient the values in iter_dict and put into a dictionary with nice names\n",
    "#iter_dict_final = {}\n",
    "#for key in key_map:\n",
    "#    iter_dict_final[key] = np.reshape(iter_dict[key_map[key]], \n",
    "#                                      (len(iter_dict[key_map[key]]), 1))\n",
    "iter_keys = ['eigen_iters', 'rel_err_k', 'abs_err_k', 'fxd_iters']\n",
    "\n",
    "key_map = {'fxd_iters' : 'Iterations =',# 'fxd_res' : '[ 0 ] =', \n",
    "           'eigen_iters' : 'Eigenvalue Iteration   ', \n",
    "           'rel_err_k' : 'relative error in k-eff of ', \n",
    "           'abs_err_k' : 'absolute error in k-eff of '}\n",
    "\n",
    "with open('output.csv', 'wb') as csvfile:\n",
    "    # write the header / problem specification information\n",
    "    writer = csv.DictWriter(csvfile, fieldnames = keys, dialect='excel', \n",
    "                            restval='',extrasaction='ignore')\n",
    "    #if not csv.Sniffer().has_header(csvfile.read(1024)):\n",
    "    writer.writeheader()\n",
    "    writer.writerow(vals)\n",
    "    \n",
    "    # Now write timing information\n",
    "    writer = csv.DictWriter(csvfile, fieldnames = time_keys, dialect='excel', \n",
    "                            restval='',extrasaction='ignore')\n",
    "    writer.writeheader()\n",
    "    writer.writerow(time_vals)\n",
    "    \n",
    "    # And iteration information\n",
    "    writer = csv.DictWriter(csvfile, fieldnames = iter_keys, dialect='excel', \n",
    "                            restval='',extrasaction='ignore')\n",
    "    writer.writeheader()\n",
    "    length = len(iter_dict[key_map[iter_keys[0]]])\n",
    "    for row_num in range(length):\n",
    "        # get a new dictionary that will contain one row of data at each new row\n",
    "        tmp_dict = {}\n",
    "        for key in iter_keys:\n",
    "            tmp_dict[key] = iter_dict[key_map[key]][row_num]\n",
    "        writer.writerow(tmp_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
