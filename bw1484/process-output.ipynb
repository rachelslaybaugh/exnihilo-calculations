{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from matplotlib import rc\n",
    "\n",
    "fontsize = 12\n",
    "\n",
    "# Make default font serif\n",
    "rc('font', family=b'serif', size=fontsize)\n",
    "# Hide legend frame, change size, make only one scatter marker show up\n",
    "rc('legend', borderpad=0.,labelspacing=0.25, fontsize=(fontsize - 1.), frameon=False, numpoints=1)\n",
    "# Default line width (e.g. for plot()) should be thinner than 1 point\n",
    "rc('patch', linewidth=0.75)\n",
    "rc('lines', linewidth=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BW1484 Core I Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k_ref = 1.00020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denovo ouput file processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "class DenovoProcessor(object):\n",
    "    \"\"\"DenovoProcessor class: processes an output file from a Denovo calculation.\n",
    "       It can read a file, print that information to csv, and do some processing\n",
    "       for highlights.\"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Set information we'll use in processing a Denovo output file\"\"\"  \n",
    "        \n",
    "        # Output variables that are in the header / problem specification\n",
    "        self.keys = ['problem_name', 'num cells I', 'num cells J', 'num cells K', 'cells', '  mesh ',\n",
    "                     'num_blocks_i', 'num_blocks_j', 'num_z_blocks', 'blocks', 'num_groups', \n",
    "                     'num upscatter groups', 'num_sets', 'domains', 'Pn_order', 'azimuthals_octant', \n",
    "                     'polars_octant', 'eq_set', 'DoF', ' tolerance', 'L2_tolerance', 'k_tolerance',\n",
    "                     'up_tol', 'eigen_solver', 'mg_preconditioner', 'relax_count', 'num_v_cycles', \n",
    "                     'relax_weight', 'ml_Pn', 'ml_az', 'ml_oct']\n",
    "        # Information about timing and processor distribution\n",
    "        self.time_keys = ['procs-per-node-x', 'procs-per-node-y', 'walltime']\n",
    "        # iteration information; place holder for iter_dict until set by solver\n",
    "        self.iter_info = np.empty([1,5])\n",
    "        self.k = {'eigenvalue of' : 1}\n",
    "        self.iter_dict = {}\n",
    "\n",
    "                \n",
    "    def parse_file(self, out_file):\n",
    "        \"\"\"Read the values for the keys from out_file\"\"\"\n",
    "        \n",
    "        # save file neame for later reporting\n",
    "        self.out_file = out_file\n",
    "        # Initalize values to match keys to None\n",
    "        self.vals = {key: None for key in self.keys}\n",
    "        self.time_vals = {key: None for key in self.time_keys}\n",
    "    \n",
    "        # Set flags and keys to use for items with duplicate entries\n",
    "        ml_flag = False\n",
    "        ml_keys = ['Pn_order', 'azimuthals_octant', 'polars_octant']\n",
    "        ml_doubles = {key: None for key in ml_keys}\n",
    "        ml_cnt = 0\n",
    "        up_db = False\n",
    "        e_solver = False\n",
    "    \n",
    "        # open the file\n",
    "        if os.path.isfile(self.out_file):\n",
    "            f = open(self.out_file, 'r')\n",
    "        else:\n",
    "            raise IOError('could not find file', self.out_file)\n",
    "   \n",
    "        # We will use an iteration count index to make sure we're putting iter info into\n",
    "        # the correct row\n",
    "        iter_count = 0\n",
    "        \n",
    "        #try: \n",
    "        # Process the file\n",
    "        for line in f: \n",
    "\n",
    "            # the iteration keys vary by eigen solver. Once we know which solver, set keys.\n",
    "            # We'll use them to map into which column in a list the data needs to be enetered into\n",
    "            if (e_solver == False):\n",
    "                if (self.vals['eigen_solver'] != None):\n",
    "                    if self.vals['eigen_solver'] == 'rayleigh_quotient':                   \n",
    "                        self.iter_dict = {'Iterations =' : 4, 'Eigenvalue Iteration   ' : 0,\n",
    "                                          'relative error in k-eff of ' : 2,\n",
    "                                          'absolute error in k-eff of ' : 3}  \n",
    "                    elif self.vals['eigen_solver'] == 'power_iteration':\n",
    "                        self.iter_dict = {'Iterations =' : 4, 'Eigenvalue iteration   ' : 0,\n",
    "                                          'relative error in k-eff of ' : 2,\n",
    "                                          'max. rel. error in fissions of ' : 3}  \n",
    "                    else:\n",
    "                        raise IOError('unknown eigenvalue solver', self.vals['eigen_solver'])\n",
    "                    e_solver = True # don't reenter this loop\n",
    "                    \n",
    "            # check for the duplicate items (that are in sub databases)\n",
    "            # before processing everything else\n",
    "            if ml_flag == True: \n",
    "                if ml_cnt != 3:\n",
    "                    for ml_key in ml_doubles:\n",
    "                        if re.search(ml_key, line):\n",
    "                            if ml_doubles[ml_key] == None:\n",
    "                                data = line.split(ml_key)\n",
    "                                ml_doubles[ml_key] = data[1].strip() \n",
    "                                ml_cnt = ml_cnt + 1\n",
    "\n",
    "            # We know that the upscatter tolerance is printed after the regular tolerance\n",
    "            # Thus, if up_db is true this tolerance is the upscatter tolerance. Also, store\n",
    "            # what's currently in tolerance to reset at the end\n",
    "            if up_db == True:\n",
    "                if re.search('tolerance', line):\n",
    "                    if self.vals['up_tol'] == None:\n",
    "                        data = line.split('tolerance')\n",
    "                        self.vals['up_tol'] = data[1].strip()\n",
    "                        tol = self.vals[' tolerance']\n",
    "\n",
    "            # Information in the header\n",
    "            for key in self.vals: \n",
    "                # check for things to set the flags\n",
    "                if re.search('multilevel_quad_db', line):\n",
    "                    ml_flag = True\n",
    "                if re.search('upscatter_db', line):\n",
    "                    up_db = True   \n",
    "                # now look for the rest of the keys\n",
    "                if re.search(key, line):\n",
    "                    data = line.split(key)\n",
    "                    self.vals[key] = data[1].strip()  \n",
    "\n",
    "            # Time and CUDA information\n",
    "            for key in self.time_vals:\n",
    "                if re.search(key, line):\n",
    "                    data = line.split(key)\n",
    "                    num = data[1].strip().split()\n",
    "                    self.time_vals[key] = num[0].strip()         \n",
    "            # Iteration information\n",
    "            for key in self.iter_dict:\n",
    "                if re.search(key, line):\n",
    "                    data = line.split(key)\n",
    "                    num = data[1].strip().split()\n",
    "                    self.iter_info[iter_count][self.iter_dict[key]] = num[0].strip()\n",
    "                    # increment the counter after reading absolute error row, add an empty row\n",
    "                    if ((key == 'absolute error in k-eff of ') or (key == 'max. rel. error in fissions of ')):\n",
    "                        iter_count = iter_count + 1\n",
    "                        self.iter_info = np.vstack((self.iter_info, np.empty([1,5])))\n",
    "            # k; need separately since it's on the same line as iteration #\n",
    "            for key in self.k:\n",
    "                if re.search(key, line):\n",
    "                    data = line.split(key)\n",
    "                    num = data[1].strip().split()\n",
    "                    self.iter_info[iter_count][self.k[key]] = num[0].strip()        \n",
    "        f.close()\n",
    "        \n",
    "        # calculate things we want in the spreadsheet\n",
    "        self.vals['cells']   = int(self.vals['num cells I']) * int(self.vals['num cells J']) * \\\n",
    "                               int(self.vals['num cells K'])\n",
    "        self.vals['blocks']  = int(self.vals['num_blocks_i']) * int(self.vals['num_blocks_j'])\n",
    "        self.vals['domains'] = int(self.vals['blocks']) * int(self.vals['num_sets'])\n",
    "        # set doubles\n",
    "        if ml_flag == True:\n",
    "            self.vals['ml_Pn']  = ml_doubles['Pn_order']\n",
    "            self.vals['ml_az']  = ml_doubles['azimuthals_octant']\n",
    "            self.vals['ml_oct'] = ml_doubles['polars_octant']\n",
    "        if up_db == True:\n",
    "            self.vals[' tolerance'] = tol\n",
    "        # the last iteration row gets filled with garbage; don't use it.\n",
    "        self.iter_info = self.iter_info[0:-1]\n",
    "        \n",
    "\n",
    "    # print the parsed information to file\n",
    "    def print_csv(self, name):\n",
    "        \"\"\"Print the read in data to name.csv\"\"\"\n",
    "\n",
    "        # itereation keys we'd like to print since they have nicer names\n",
    "        iter_keys = ['eigen_iters', 'k', 'rel_err_k', 'abs_err_k', 'fxd_iters']\n",
    "        # store filename for printing later\n",
    "        self.csv = name \n",
    "\n",
    "        with open(self.csv+'.csv', 'wb') as csvfile:\n",
    "            # write the header / problem specification information\n",
    "            writer = csv.DictWriter(csvfile, fieldnames = self.keys, dialect='excel', \n",
    "                                    restval='',extrasaction='ignore')\n",
    "            #if not csv.Sniffer().has_header(csvfile.read(1024)):\n",
    "            writer.writeheader()\n",
    "            writer.writerow(self.vals)\n",
    "    \n",
    "            # Now write timing information\n",
    "            writer = csv.DictWriter(csvfile, fieldnames = self.time_keys, dialect='excel', \n",
    "                                    restval='',extrasaction='ignore')\n",
    "            writer.writeheader()\n",
    "            writer.writerow(self.time_vals)\n",
    "    \n",
    "            # And iteration information\n",
    "            # we need a regular writer for the list\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow(iter_keys)\n",
    "            writer.writerows(self.iter_info)\n",
    "            print \"Wrote csv file\", self.csv, \"\\n\"\n",
    "            \n",
    "            \n",
    "    # We want the k on the last iteration, the total number of fixed iters, last rel and abs err\n",
    "    # eigen solver, preconditioner data, wall time\n",
    "    def highlights(self):\n",
    "        \"\"\"Print some highlights we care about most\"\"\"\n",
    "        \n",
    "        # Get total number of inner iterations the last row of iteration information\n",
    "        end_info = self.iter_info[-1]\n",
    "        # sum the total number of inner iterations\n",
    "        total_inner = int(np.sum(self.iter_info, axis=0)[self.iter_dict['Iterations =']])\n",
    "        \n",
    "        # print\n",
    "        print \"From results file\", self.out_file, \"\\n\"    \n",
    "        if self.vals['eigen_solver'] == 'rayleigh_quotient':\n",
    "            print \"After \",  self.time_vals['walltime'], \"minutes,\", \\\n",
    "            self.iter_info[-1][self.iter_dict['Eigenvalue Iteration   ']], \"eigenvalue iterations, and\", \\\n",
    "            total_inner, \"total inner iterations,\"\n",
    "            print \"k was\", self.iter_info[:][self.k['eigenvalue of']], \"with relative error\",\\\n",
    "            self.iter_info[-1][self.iter_dict['relative error in k-eff of ']], \"and absolute error\",\\\n",
    "            self.iter_info[-1][self.iter_dict['absolute error in k-eff of ']]\n",
    "        elif self.vals['eigen_solver'] == 'power_iteration':\n",
    "            print \"After \",  self.time_vals['walltime'], \"minutes,\", \\\n",
    "            self.iter_info[-1][self.iter_dict['Eigenvalue iteration   ']], \"eigenvalue iterations, and\", \\\n",
    "            total_inner, \"total inner iterations,\"\n",
    "            print \"k was\", self.iter_info[-1][self.k['eigenvalue of']], \"with relative error\",\\\n",
    "            self.iter_info[-1][self.iter_dict['relative error in k-eff of ']], \"and max. rel. error in fissions\",\\\n",
    "            self.iter_info[-1][self.iter_dict['max. rel. error in fissions of ']]        \n",
    "        else:\n",
    "            raise IOError('unknown eigenvalue solver', self.vals['eigen_solver'])\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process a bunch of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote csv file /home/slayer/Dropbox/Research/Calculations/Denovo/bw1484/bw1484_m20g8qr612_nosets \n",
      "\n",
      "From results file /home/slayer/Dropbox/Research/Calculations/Denovo/bw1484/bw1484_m20g8qr612_nosets.out \n",
      "\n",
      "After  21630 minutes, 3.0 eigenvalue iterations, and 46 total inner iterations,\n",
      "k was [  2.           0.09167725   9.957958     0.9129182   22.        ] with relative error 0.01725755 and absolute error 0.01733686\n",
      "\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "Wrote csv file /home/slayer/Dropbox/Research/Calculations/Denovo/bw1484/bw1484_m20g8qr612 \n",
      "\n",
      "From results file /home/slayer/Dropbox/Research/Calculations/Denovo/bw1484/bw1484_m20g8qr612.out \n",
      "\n",
      "After  21612 minutes, 4.0 eigenvalue iterations, and 148 total inner iterations,\n",
      "k was [  2.           0.08774086  10.44698      0.9166266   23.        ] with relative error 0.003971347 and absolute error 0.00405822\n",
      "\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "Wrote csv file /home/slayer/Dropbox/Research/Calculations/Denovo/bw1484/bw1484_m20g8qr612_pi \n",
      "\n",
      "From results file /home/slayer/Dropbox/Research/Calculations/Denovo/bw1484/bw1484_m20g8qr612_pi.out \n",
      "\n",
      "After  21607 minutes, 5.0 eigenvalue iterations, and 375 total inner iterations,\n",
      "k was 1.0238926044 with relative error 0.003272098 and max. rel. error in fissions 2176.228\n",
      "\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "Wrote csv file /home/slayer/Dropbox/Research/Calculations/Denovo/bw1484/bw1484_m20g8qr612_w1.1r3v2 \n",
      "\n",
      "From results file /home/slayer/Dropbox/Research/Calculations/Denovo/bw1484/bw1484_m20g8qr612_w1.1r3v2.out \n",
      "\n",
      "After  21626 minutes, 5.0 eigenvalue iterations, and 147 total inner iterations,\n",
      "k was [  2.           0.11964619   7.406432     0.8861514   19.        ] with relative error 0.0007715661 and absolute error 0.0007918378\n",
      "\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "Wrote csv file /home/slayer/Dropbox/Research/Calculations/Denovo/bw1484/bw1484_small \n",
      "\n",
      "From results file /home/slayer/Dropbox/Research/Calculations/Denovo/bw1484/bw1484_small.out \n",
      "\n",
      "After  7211 minutes, 59.0 eigenvalue iterations, and 2679 total inner iterations,\n",
      "k was [  2.           0.06380217  14.90793      0.951158    24.        ] with relative error 0.01693561 and absolute error 0.01748288\n",
      "\n",
      "\n",
      "-----------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Name of the file containing the output we want to process \n",
    "file_location = '/home/slayer/Dropbox/Research/Calculations/Denovo/bw1484'\n",
    "\n",
    "# Get a DenovoProcessor\n",
    "processor = DenovoProcessor()\n",
    "\n",
    "# Make a list of files to process\n",
    "files = ['bw1484_m20g8qr612_nosets.out', 'bw1484_m20g8qr612.out', 'bw1484_m20g8qr612_pi.out', \n",
    "         'bw1484_m20g8qr612_w1.1r3v2.out', 'bw1484_small.out']\n",
    "#files=['bw1484_m20g8qr612_pi.out'] \n",
    "\n",
    "for file_name in files:\n",
    "    \n",
    "    full_out_file = os.path.join(file_location, file_name)\n",
    "\n",
    "    # parse the file, and write to csv\n",
    "    processor.__init__()\n",
    "    processor.parse_file(full_out_file)\n",
    "    processor.print_csv(full_out_file[0:-4])\n",
    "    processor.highlights()\n",
    "    print \"\\n\\n-----------------------------\\n\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
